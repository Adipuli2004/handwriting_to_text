{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "eDRB_l7xUXBL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip new_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13RjuaAyzxLK",
        "outputId": "89aa0d32-f68b-4d1d-c385-731809cc07fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  new_data.zip\n",
            "replace new_data/a.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense,Conv1D,MaxPooling1D,Flatten,Dropout,GlobalAveragePooling1D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Function to preprocess the data\n",
        "def preprocess_data(df):\n",
        "    groups = df.groupby('Output')\n",
        "    sequences = []\n",
        "    for name, group in groups:\n",
        "        indices = group['Output'].values\n",
        "        change_indices = np.where(indices[:-1] != indices[1:])[0] + 1\n",
        "        if len(change_indices) > 0:\n",
        "            sub_sequences = np.split(group.iloc[:, 1:], change_indices)\n",
        "        else:\n",
        "            sub_sequences = [group.iloc[:, 1:]]\n",
        "        sequences.extend(sub_sequences)  # Append sequences to the list\n",
        "    return sequences\n",
        "\n",
        "# Load data and preprocess\n",
        "l = 'a b c d e f g h i j k l m n o p q r s t u v w x y z'.split()\n",
        "all_sequences = []\n",
        "labels = []\n",
        "\n",
        "for letter in l:\n",
        "    filename = f\"/content/new_data/{letter}.csv\"\n",
        "    df = pd.read_csv(filename)\n",
        "    df.drop(0,axis=0,inplace=True)\n",
        "    sequences = preprocess_data(df)\n",
        "    all_sequences.extend(sequences)  # Extend the list with sequences from the current file\n",
        "    labels.extend([letter] * len(sequences))  # Assign labels for sequences from the current file\n",
        "\n",
        "# Pad sequences to ensure they have the same length\n",
        "max_length = max([len(seq) for seq in all_sequences])\n",
        "padded_sequences = pad_sequences(all_sequences, maxlen=max_length, padding='post', dtype='float32')\n",
        "\n",
        "# Convert sequences and labels to numpy arrays\n",
        "X = np.array(padded_sequences)\n",
        "y = np.array(labels)\n",
        "\n",
        "# Shuffle sequences and labels simultaneously while maintaining correspondence\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "train_indices=[]\n",
        "test_indices=[]\n",
        "for i in range(len(X)):\n",
        "  if i%5==0:\n",
        "    test_indices.append(i)\n",
        "  else:\n",
        "    train_indices.append(i)\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "X_test,y_test,X_train,y_train=X[test_indices],y_categorical[test_indices],X[train_indices],y_categorical[train_indices]"
      ],
      "metadata": {
        "id": "P5rQxzWECWxq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(32,kernel_size=2,strides=1,activation='gelu'))\n",
        "model.add(Conv1D(32,kernel_size=2,strides=1,activation='gelu'))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model.add(Conv1D(32,kernel_size=2,strides=1,activation='gelu'))\n",
        "model.add(Conv1D(32,kernel_size=2,strides=1,activation='gelu'))\n",
        "model.add(MaxPooling1D(pool_size=(2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64,activation='gelu'))\n",
        "\n",
        "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Change this line\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,validation_data=(X_test,y_test), epochs=25, batch_size=32,verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# Decode predicted labels\n",
        "y_pred_decoded = label_encoder.inverse_transform(y_pred_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred_labels)\n",
        "print(\"Test Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rfYWeZYVE0Q",
        "outputId": "2003fa3d-3997-4fb5-c0b9-cb98090a4f8e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "4/4 [==============================] - 2s 132ms/step - loss: 3.6585 - accuracy: 0.0385 - val_loss: 3.3799 - val_accuracy: 0.0385\n",
            "Epoch 2/25\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 2.5073 - accuracy: 0.3173 - val_loss: 3.2284 - val_accuracy: 0.0769\n",
            "Epoch 3/25\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 1.9150 - accuracy: 0.6442 - val_loss: 3.1519 - val_accuracy: 0.1923\n",
            "Epoch 4/25\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 1.2844 - accuracy: 0.8173 - val_loss: 3.2317 - val_accuracy: 0.2308\n",
            "Epoch 5/25\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.7277 - accuracy: 0.8942 - val_loss: 3.4425 - val_accuracy: 0.1923\n",
            "Epoch 6/25\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.3361 - accuracy: 0.9615 - val_loss: 3.6996 - val_accuracy: 0.1538\n",
            "Epoch 7/25\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.1310 - accuracy: 1.0000 - val_loss: 4.0666 - val_accuracy: 0.1923\n",
            "Epoch 8/25\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 4.5170 - val_accuracy: 0.1923\n",
            "Epoch 9/25\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 4.8707 - val_accuracy: 0.1923\n",
            "Epoch 10/25\n",
            "4/4 [==============================] - 0s 67ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 5.1118 - val_accuracy: 0.1538\n",
            "Epoch 11/25\n",
            "4/4 [==============================] - 0s 65ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 5.2970 - val_accuracy: 0.1538\n",
            "Epoch 12/25\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.4392 - val_accuracy: 0.1154\n",
            "Epoch 13/25\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.5606 - val_accuracy: 0.1154\n",
            "Epoch 14/25\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.6478 - val_accuracy: 0.1538\n",
            "Epoch 15/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 9.8726e-04 - accuracy: 1.0000 - val_loss: 5.7100 - val_accuracy: 0.1923\n",
            "Epoch 16/25\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 7.9305e-04 - accuracy: 1.0000 - val_loss: 5.7536 - val_accuracy: 0.1923\n",
            "Epoch 17/25\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 6.8001e-04 - accuracy: 1.0000 - val_loss: 5.7818 - val_accuracy: 0.1923\n",
            "Epoch 18/25\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 5.9711e-04 - accuracy: 1.0000 - val_loss: 5.8007 - val_accuracy: 0.1923\n",
            "Epoch 19/25\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 5.4075e-04 - accuracy: 1.0000 - val_loss: 5.8137 - val_accuracy: 0.1923\n",
            "Epoch 20/25\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 4.9526e-04 - accuracy: 1.0000 - val_loss: 5.8208 - val_accuracy: 0.1923\n",
            "Epoch 21/25\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 4.6367e-04 - accuracy: 1.0000 - val_loss: 5.8263 - val_accuracy: 0.1923\n",
            "Epoch 22/25\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 4.3586e-04 - accuracy: 1.0000 - val_loss: 5.8303 - val_accuracy: 0.1923\n",
            "Epoch 23/25\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 4.1166e-04 - accuracy: 1.0000 - val_loss: 5.8339 - val_accuracy: 0.1923\n",
            "Epoch 24/25\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 3.9390e-04 - accuracy: 1.0000 - val_loss: 5.8379 - val_accuracy: 0.1923\n",
            "Epoch 25/25\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 3.7723e-04 - accuracy: 1.0000 - val_loss: 5.8414 - val_accuracy: 0.1923\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.8414 - accuracy: 0.1923\n",
            "Test Accuracy: 0.19230769574642181\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "Test Accuracy: 0.19230769230769232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_1.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWRYqGmkRBjQ",
        "outputId": "41e27ede-41e2-4c6e-986a-a17fd138ea65"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}